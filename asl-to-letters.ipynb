{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4770309,"sourceType":"datasetVersion","datasetId":2761071}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"char_list = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\nchar_dict = {i: char_list[i] for i in range(len(char_list))}\n\nprint(char_dict)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-29T05:16:56.284486Z","iopub.execute_input":"2025-06-29T05:16:56.284756Z","iopub.status.idle":"2025-06-29T05:16:56.295953Z","shell.execute_reply.started":"2025-06-29T05:16:56.284729Z","shell.execute_reply":"2025-06-29T05:16:56.294952Z"}},"outputs":[{"name":"stdout","text":"{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install mediapipe\nimport mediapipe as mp\n\nmp_hands = mp.solutions.hands\nhands = mp_hands.Hands(static_image_mode=True, max_num_hands=1)\nmp_drawing = mp.solutions.drawing_utils","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T05:17:59.564553Z","iopub.execute_input":"2025-06-29T05:17:59.565345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\npath=\"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T05:21:07.374855Z","iopub.execute_input":"2025-06-29T05:21:07.375212Z","iopub.status.idle":"2025-06-29T05:21:07.379355Z","shell.execute_reply.started":"2025-06-29T05:21:07.375186Z","shell.execute_reply":"2025-06-29T05:21:07.378413Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import cv2\n\nX=[]\nY=[]\nlabel=[]\n\nk=0\n\nfor i in char_list:\n    path1=os.path.join(path,i)\n    for j in os.listdir(path1):\n        image_path = os.path.join(path1, j)\n        image = cv2.imread(image_path)\n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        results = hands.process(image_rgb)\n        if results.multi_hand_landmarks:\n            for hand_landmarks in results.multi_hand_landmarks:\n                mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n                x1=[]\n                y1=[]\n                for idx, landmark in enumerate(hand_landmarks.landmark):\n                    h, w, _ = image.shape\n                    x, y = int(landmark.x * w), int(landmark.y * h)\n                    x1.append(x)\n                    y1.append(y)\n                X.append(x1)\n                Y.append(y1)\n                label.append(k)\n        else:\n            continue\n    k=k+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T05:21:08.345146Z","iopub.execute_input":"2025-06-29T05:21:08.345425Z","iopub.status.idle":"2025-06-29T05:25:40.670816Z","shell.execute_reply.started":"2025-06-29T05:21:08.345406Z","shell.execute_reply":"2025-06-29T05:25:40.669928Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1751174468.596762     107 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\n\n# Create feature vectors by keeping X and Y separate\nfeatures = [x + y for x, y in zip(X, Y)]  # x: list of X coords, y: list of Y coords\n\n# Create DataFrame\ndf = pd.DataFrame(features)\ndf['label'] = label  # Append label as the target column\n\n# Split into features and labels\nX_df = df.drop('label', axis=1)\ny_df = df['label']\n\n# Train-test split\nx_train, x_test, y_train, y_test = train_test_split(X_df, y_df, test_size=0.2, random_state=42)\n\n# Train Random Forest model\nmodel = RandomForestClassifier()\nmodel.fit(x_train, y_train)\n\n# Predict and evaluate\ny_pred = model.predict(x_test)\naccuracy = accuracy_score(y_test, y_pred)\nprint(\"Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T05:26:41.291759Z","iopub.execute_input":"2025-06-29T05:26:41.292122Z","iopub.status.idle":"2025-06-29T05:26:42.659444Z","shell.execute_reply.started":"2025-06-29T05:26:41.292079Z","shell.execute_reply":"2025-06-29T05:26:42.658634Z"}},"outputs":[{"name":"stdout","text":"Accuracy: 0.9744245524296675\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\n\ndef predict_asl_letter(model, image_path, char_dict):\n    mp_hands = mp.solutions.hands\n    hands = mp_hands.Hands(\n        static_image_mode=True, \n        max_num_hands=1,\n        min_detection_confidence=0.1,\n        min_tracking_confidence=0.1\n    )\n    \n    image = cv2.imread(image_path)\n    if image is None:\n        return \"Error: Could not load image\"\n    \n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    results = hands.process(image_rgb)\n    \n    if results.multi_hand_landmarks:\n        for hand_landmarks in results.multi_hand_landmarks:\n            x_coords = []\n            y_coords = []\n            \n            for landmark in hand_landmarks.landmark:\n                h, w, _ = image.shape\n                x, y = int(landmark.x * w), int(landmark.y * h)\n                x_coords.append(x)\n                y_coords.append(y)\n            \n            features = x_coords + y_coords\n            prediction = model.predict([features])[0]\n            predicted_letter = char_dict[prediction]\n            \n            return predicted_letter\n    else:\n        return \"No hand detected\"\n\n# Test with your image\nimage_path = \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/N/11.jpg\"\n\n# Your char_dict from training\nchar_list = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\nchar_dict = {i: char_list[i] for i in range(len(char_list))}\n\nresult = predict_asl_letter(model, image_path, char_dict)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:10:04.944842Z","iopub.execute_input":"2025-06-29T06:10:04.945197Z","iopub.status.idle":"2025-06-29T06:10:05.095845Z","shell.execute_reply.started":"2025-06-29T06:10:04.945173Z","shell.execute_reply":"2025-06-29T06:10:05.094715Z"}},"outputs":[{"name":"stdout","text":"N\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1751177405.017764     382 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177405.069800     382 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import cv2\nimport mediapipe as mp\nimport os\nimport warnings\nimport logging\nimport sys\nfrom contextlib import redirect_stderr\nfrom io import StringIO\n\n# Suppress all warnings and logs\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\nos.environ['GLOG_minloglevel'] = '3'\nwarnings.filterwarnings('ignore')\nlogging.getLogger().setLevel(logging.ERROR)\n\ndef predict_asl_letter(model, image_path, char_dict):\n    mp_hands = mp.solutions.hands\n    \n    # Suppress stderr during MediaPipe operations\n    with redirect_stderr(StringIO()):\n        hands = mp_hands.Hands(\n            static_image_mode=True, \n            max_num_hands=1,\n            min_detection_confidence=0.1,\n            min_tracking_confidence=0.1\n        )\n        \n        image = cv2.imread(image_path)\n        if image is None:\n            return \"?\"\n        \n        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        results = hands.process(image_rgb)\n    \n    if results.multi_hand_landmarks:\n        for hand_landmarks in results.multi_hand_landmarks:\n            x_coords = []\n            y_coords = []\n            \n            for landmark in hand_landmarks.landmark:\n                h, w, _ = image.shape\n                x, y = int(landmark.x * w), int(landmark.y * h)\n                x_coords.append(x)\n                y_coords.append(y)\n            \n            features = x_coords + y_coords\n            prediction = model.predict([features])[0]\n            predicted_letter = char_dict[prediction]\n            \n            return predicted_letter\n    else:\n        return \"?\"\n\ndef predict_word_from_images(model, image_paths, char_dict):\n    word = \"\"\n    for image_path in image_paths:\n        letter = predict_asl_letter(model, image_path, char_dict)\n        word += letter\n    return word\n\n# Your char_dict from training\nchar_list = [chr(i) for i in range(ord('A'), ord('Z') + 1)]\nchar_dict = {i: char_list[i] for i in range(len(char_list))}\n\n# Example with list of image paths\nimage_paths = [\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/H/11.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/E/105.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/L/11.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/L/10.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/O/103.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/E/105.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/V/103.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/E/109.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/R/104.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/Y/104.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/O/103.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/N/104.jpg\",\n    \"/kaggle/input/american-sign-language-asl/American Sign Language (ASL)/data/E/104.jpg\",\n]\n\nresult = predict_word_from_images(model, image_paths, char_dict)\nprint(result)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-29T06:17:16.349900Z","iopub.execute_input":"2025-06-29T06:17:16.350581Z","iopub.status.idle":"2025-06-29T06:17:18.125155Z","shell.execute_reply.started":"2025-06-29T06:17:16.350556Z","shell.execute_reply":"2025-06-29T06:17:18.124135Z"}},"outputs":[{"name":"stderr","text":"W0000 00:00:1751177836.424763     521 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.475612     521 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.561916     525 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.606460     523 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.696625     529 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.745019     527 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.829779     533 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.874501     533 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177836.960145     537 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.009047     537 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.096905     541 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.143482     541 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.231577     545 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.280160     545 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.365838     549 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.416374     549 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.502164     553 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.550407     553 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.635264     558 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.683207     558 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.770296     561 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.821458     561 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.912385     565 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177837.960173     565 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"},{"name":"stdout","text":"HELLOEVERYONE\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1751177838.053068     569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\nW0000 00:00:1751177838.099921     569 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","output_type":"stream"}],"execution_count":49},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}